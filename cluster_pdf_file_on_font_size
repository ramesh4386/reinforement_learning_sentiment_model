#pip install pdfplumber 


import pandas as pd  
import pdfplumber  
  
# open the PDF file  
with pdfplumber.open('example.pdf') as pdf:  
    # iterate over each page in the PDF file  
    clusters = {}  
    for page in pdf.pages:  
        # get the text content of the page with font size information  
        chars = page.chars  
          
        # iterate over each character in the page  
        for char in chars:  
            # get the font size of the character  
            font_size = char["size"]  
              
            # add the character to the appropriate cluster based on font size  
            if font_size in clusters:  
                clusters[font_size].append(char["text"])  
            else:  
                clusters[font_size] = [char["text"]]  
      
    # create a Pandas DataFrame with the font size and cluster of text  
    df = pd.DataFrame({'size': [], 'cluster': []})  
    for font_size, chars in clusters.items():  
        # join the characters in each cluster into a single string  
        cluster_text = ''.join(chars)  
          
        # add the font size and cluster text to the DataFrame  
        df = df.append({'size': font_size, 'cluster': cluster_text}, ignore_index=True)  
      
    # sort the DataFrame by font size in ascending order  
    df = df.sort_values(by='size')  
      
    # print the resulting DataFrame  
    print(df)  

###################################################content_extraction#######################

import re  
import pdfplumber  
  
def is_toc_entry(line):  
    # Define a regular expression pattern for table of content entries  
    pattern = r'^\s*\d+(\.\d+)*\s+.*\s+\d+\s*$'  
    return bool(re.match(pattern, line))  
  
# open the PDF file  
with pdfplumber.open('example.pdf') as pdf:  
    # Check each page for table of content entries  
    toc_lines = []  
    for page in pdf.pages:  
        # Extract text from the page  
        page_text = page.extract_text()  
          
        # Check each line for a table of content entry  
        for line in page_text.split('\n'):  
            if is_toc_entry(line):  
                toc_lines.append(line)  
      
    # Print the table of contents  
    toc = '\n'.join(toc_lines)  
    print(toc)  

#############################################################################################

import re  
import pdfplumber  
  
def is_toc_entry(line):  
    # Define a regular expression pattern for table of content entries  
    pattern = r'^\s*\d+\s+.*[A-Za-z]+.*\s+\d+\s*$'  
    return bool(re.match(pattern, line))  
  
# open the PDF file  
with pdfplumber.open('example.pdf') as pdf:  
    # Check each page for table of content entries  
    toc_lines = []  
    for page in pdf.pages:  
        # Extract text from the page  
        page_text = page.extract_text()  
          
        # Check each line for a table of content entry  
        for line in page_text.split('\n'):  
            if is_toc_entry(line):  
                toc_lines.append(line)  
      
    # Print the table of contents  
    toc = '\n'.join(toc_lines)  
    print(toc)  

##################################################################################

import re  
import pdfplumber  
  
def is_toc_entry(line):  
    # Define a regular expression pattern for table of content entries  
    pattern = r'^\s*\d+\s+.*[A-Za-z]+.*\s+\d+\s*$'  
    return bool(re.match(pattern, line))  
  
# open the PDF file  
with pdfplumber.open('example.pdf') as pdf:  
    # Check each page for table of content entries  
    toc_lines = []  
      
    # Limit the analysis to the first 10 pages  
    for page_number in range(min(10, len(pdf.pages))):  
        page = pdf.pages[page_number]  
          
        # Extract text from the page  
        page_text = page.extract_text()  
          
        # Check each line for a table of content entry  
        for line in page_text.split('\n'):  
            if is_toc_entry(line):  
                toc_lines.append(line)  
      
    # Print the table of contents  
    toc = '\n'.join(toc_lines)  
    print(toc)  


#######################################################################

import re  
import pdfplumber  
  
def is_toc_entry(line):  
    # Define a regular expression pattern for table of content entries  
    pattern = r'^\s*(\d+(\.\d+)*|\w+)\s+.*[A-Za-z]+.*\s+\d+\s*$'  
    return bool(re.match(pattern, line))  
  
def is_header_or_footer(line, header_footer_keywords):  
    for keyword in header_footer_keywords:  
        if keyword.lower() in line.lower():  
            return True  
    return False  
  
# List of common header/footer keywords to ignore  
header_footer_keywords = ["Chapter", "Contents", "Page", "Index"]  
  
# open the PDF file  
with pdfplumber.open('example.pdf') as pdf:  
    # Check each page for table of content entries  
    toc_lines = []  
      
    # Limit the analysis to the first 10 pages  
    for page_number in range(min(10, len(pdf.pages))):  
        page = pdf.pages[page_number]  
          
        # Extract text from the page  
        page_text = page.extract_text()  
          
        # Check each line for a table of content entry  
        consecutive_toc_lines = []  
        for line in page_text.split('\n'):  
            if is_toc_entry(line) and not is_header_or_footer(line, header_footer_keywords):  
                consecutive_toc_lines.append(line)  
            else:  
                # If the number of consecutive lines is greater than a threshold (e.g., 3), consider it as a TOC  
                if len(consecutive_toc_lines) > 3:  
                    toc_lines.extend(consecutive_toc_lines)  
                consecutive_toc_lines = []  
      
    # Print the table of contents  
    toc = '\n'.join(toc_lines)  
    print(toc)  

###############################################################

import pandas as pd  
import pdfplumber  
  
# Open the PDF file  
with pdfplumber.open('example.pdf') as pdf:  
    # Initialize an empty list to store the header and footer information  
    header_footer_info = []  
      
    # Iterate over each page in the PDF  
    for page_number in range(len(pdf.pages)):  
        page = pdf.pages[page_number]  
          
        # Extract the header and footer text and font size from the first and last text boxes on the page  
        header_text = page.extract_text().split('\n')[0]  
        footer_text = page.extract_text().split('\n')[-1]  
          
        words = page.extract_words()  
        header_font_size = words[0]['size'] if words else None  
        footer_font_size = words[-1]['size'] if words else None  
          
        # Append the header and footer information to the list  
        header_footer_info.append({'Page': page_number+1, 'Header Text': header_text, 'Header Font Size': header_font_size, 'Footer Text': footer_text, 'Footer Font Size': footer_font_size})  
      
    # Convert the list to a Pandas DataFrame  
    df = pd.DataFrame(header_footer_info)  
      
    # Print the DataFrame  
    print(df)  
###########################headings###################
import pandas as pd  
import pdfplumber  
  
# Function to identify heading level based on font size  
def get_heading_level(font_size, font_sizes):  
    for i, size in enumerate(sorted(font_sizes, reverse=True)):  
        if font_size == size:  
            return i + 1  
    return None  
  
# Open the PDF file  
with pdfplumber.open('example.pdf') as pdf:  
    headings_info = []  
  
    # Iterate over each page in the PDF  
    for page_number in range(len(pdf.pages)):  
        page = pdf.pages[page_number]  
        words = page.extract_words()  
  
        # Identify unique font sizes on the page  
        font_sizes = list(set(word.get('size', None) for word in words if word.get('size', None) is not None))  
  
        # Extract the headings and font sizes  
        for word in words:  
            if word['text'].isupper():  
                font_size = word.get('size', None)  
                if font_size is not None:  
                    heading_level = get_heading_level(font_size, font_sizes)  
                    headings_info.append({  
                        'Page': page_number + 1,  
                        'Text': word['text'],  
                        'Font Size': font_size,  
                        'Heading Level': f'H{heading_level}'  
                    })  
  
    # Convert the list to a Pandas DataFrame  
    df = pd.DataFrame(headings_info)  
  
    # Print the DataFrame  
    print(df)  


  
    
################
import pandas as pd  
import pdfplumber  
  
# Function to identify heading level based on font size  
def get_heading_level(font_size, font_sizes):  
    for i, size in enumerate(sorted(font_sizes, reverse=True)):  
        if font_size == size:  
            return i + 1  
    return None  
  
# Open the PDF file  
with pdfplumber.open('example.pdf') as pdf:  
    headings_info = []  
  
    # Iterate over each page in the PDF  
    for page_number in range(len(pdf.pages)):  
        page = pdf.pages[page_number]  
        words = page.extract_words()  
          
        # Identify unique font sizes on the page  
        font_sizes = list(set(word['size'] for word in words))  
          
        # Calculate the average font size  
        avg_font_size = sum(word['size'] for word in words) / len(words)  
  
        # Extract the headings and font sizes  
        for word in words:  
            if word['text'].isupper() and word['size'] > avg_font_size:  
                font_size = word['size']  
                heading_level = get_heading_level(font_size, font_sizes)  
                headings_info.append({  
                    'Page': page_number + 1,  
                    'Text': word['text'],  
                    'Font Size': font_size,  
                    'Heading Level': f'H{heading_level}'  
                })  
  
    # Convert the list to a Pandas DataFrame  
    df = pd.DataFrame(headings_info)  
  
    # Print the DataFrame  
    print(df)  








